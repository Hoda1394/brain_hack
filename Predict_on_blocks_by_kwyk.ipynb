{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_on_blocks_by_kwyk.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbweNfekB0qI+y4/SbYXuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoda1394/brain_hack/blob/master/Predict_on_blocks_by_kwyk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGehqsNyH8mu"
      },
      "source": [
        "!wget -O- http://neuro.debian.net/lists/bionic.us-nh.full | tee /etc/apt/sources.list.d/neurodebian.sources.list \\\n",
        " && apt-key adv --recv-keys --keyserver hkp://pool.sks-keyservers.net:80 0xA5D32F012649A5A9 \\\n",
        " && apt-get update \\\n",
        " && apt-get install git-annex-standalone git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqhuIsnmISzS"
      },
      "source": [
        "!git-annex version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa9yc89-ITxs"
      },
      "source": [
        "!pip install --no-cache-dir nilearn datalad datalad-osf\n",
        "!pip install --no-cache-dir https://github.com/neuronets/nobrainer/tarball/master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl5B31XJIWzg"
      },
      "source": [
        "import nobrainer\n",
        "!datalad clone https://github.com/neuronets/trained-models && \\\n",
        "  cd trained-models && git-annex enableremote osf-storage && \\\n",
        "  datalad get -s osf-storage neuronets/kwyk/0.4.1/all_50_bvwn_multi_prior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDidIMSDIcA9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import nibabel as nib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCKQZfuwIiBK"
      },
      "source": [
        "# prepare your data \n",
        "# upload your data\n",
        "# use functions nib.processing.conform to conform the size to 32 block\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "image_path = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0gSAW72IrvK"
      },
      "source": [
        "# load the model\n",
        "model_path = \"trained-models/neuronets/kwyk/0.4.1/all_50_bvwn_multi_prior/\"\n",
        "model = tf.saved_model.load(model_path)\n",
        "model = model.signatures['serving_default']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IONP7P3OJGAw"
      },
      "source": [
        "# predict from an input block\n",
        "\n",
        "from nobrainer.utils import StreamingStats\n",
        "import numpy as np\n",
        "\n",
        "img = nib.load(filepath)\n",
        "inputs = np.asarray(img.dataobj)\n",
        "img.uncache()\n",
        "inputs = inputs.astype(np.float32)\n",
        "\n",
        "print(\"Normalizer being used {n}\".format(n = normalizer))\n",
        "    if normalizer:\n",
        "        features = normalizer(inputs)\n",
        "        print(features.mean())\n",
        "        print(features.std())\n",
        "    else:\n",
        "        features = inputs\n",
        "\n",
        "# Add a dimension for single channel.\n",
        "features = features[..., None]\n",
        "data = tf.convert_to_tensor(features)\n",
        "prediction = model(data)\n",
        "\n",
        "out = prediction['probabilities']\n",
        "print(\"output size\",out.shape)\n",
        "\n",
        "# return in the form of a nifti image\n",
        "output = nib.spatialimages.SpatialImage(\n",
        "          dataobj=out, affine=img.affine, header=img.header, extra=img.extra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVECkN9UNA7b"
      },
      "source": [
        "# resize back the output image by nib.processing.resample_from_to or any other tool\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx8bTy-mMk-P"
      },
      "source": [
        "# plot output with nilearn or just numpy\n",
        "from nilearn import plotting\n",
        "\n",
        "plotting.plot_roi(out, bg_img=image_path, alpha=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBSheA0gMffS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}